# üìö Glosario de T√©rminos

Definiciones y explicaciones de t√©rminos t√©cnicos utilizados en el proyecto.

## ü§ñ Inteligencia Artificial y Modelos

### **Whisper**
Modelo de transcripci√≥n autom√°tica de voz a texto desarrollado por OpenAI. Entrenado en 680,000 horas de audio multiling√ºe, ofrece transcripci√≥n robusta y precisa para m√∫ltiples idiomas.

**Variantes disponibles:**
- `tiny`: 39 MB, m√°s r√°pido pero menor precisi√≥n
- `small`: 244 MB, equilibrio entre velocidad y precisi√≥n  
- `medium`: 769 MB, buena precisi√≥n para uso general
- `large`: 1550 MB, alta precisi√≥n
- `large-v3`: √öltima versi√≥n optimizada

### **faster-whisper**
Implementaci√≥n optimizada de Whisper usando CTranslate2. Ofrece:
- 4x m√°s velocidad que la implementaci√≥n original
- Menor uso de memoria
- Soporte completo para GPU CUDA
- Compatibilidad total con modelos Whisper

### **GPT-4o (OpenAI)**
Modelo de lenguaje multimodal de OpenAI optimizado para conversaciones y tareas de texto. Caracter√≠sticas:
- L√≠mite de contexto: 128,000 tokens
- L√≠mite de salida configurable hasta 16,384 tokens
- Procesamiento r√°pido y coherente
- API REST estable

### **GPT-OSS (Ollama)**
Modelo de c√≥digo abierto compatible con GPT ejecutado localmente via Ollama:
- Tama√±o: ~13 GB descargado
- Ejecuci√≥n completamente local
- Sin l√≠mites de tokens por API
- Privacidad total de datos

### **DeepSeek-R1**
Modelo de razonamiento avanzado de DeepSeek ejecutado via Ollama:
- Tama√±o: ~5.2 GB
- Especializado en razonamiento paso a paso
- Contexto extendido: 32,768 tokens
- Salida optimizada: 16,384 tokens

## üíª Hardware y GPU

### **CUDA (Compute Unified Device Architecture)**
Plataforma de computaci√≥n paralela y API de NVIDIA que permite usar GPUs para computaci√≥n general:
- Acelera significativamente el procesamiento de audio/v√≠deo
- Especialmente efectivo para modelos de deep learning
- Requiere GPU NVIDIA compatible

### **RTX 5090**
GPU de alta gama de NVIDIA con especificaciones excepcionales:
- **VRAM**: 31.8 GB GDDR7
- **CUDA Cores**: 21,760
- **Rendimiento**: 7-8x tiempo real en transcripci√≥n
- **Compute Capability**: 8.9+

### **VRAM (Video RAM)**
Memoria dedicada de la tarjeta gr√°fica utilizada para:
- Almacenar modelos de IA (Whisper requiere 1-6 GB seg√∫n versi√≥n)
- Cache de datos durante procesamiento
- Buffers de audio/v√≠deo temporales

### **Tensor Cores**
Unidades especializadas en GPUs NVIDIA para acelerar operaciones de:
- Multiplicaci√≥n de matrices
- Inferencia de redes neuronales
- Procesamiento de modelos transformer como Whisper

## üèóÔ∏è Arquitectura del Sistema

### **Motor de IA**
Componente que gestiona la comunicaci√≥n con un servicio de IA espec√≠fico:
- **Motor OpenAI**: Conecta con API de OpenAI
- **Motor Ollama**: Conecta con servidor Ollama local
- **Motor DeepSeek**: Especializaci√≥n de Ollama para DeepSeek-R1

### **Prompt Maestro**
Template unificado que:
- Define la estructura de salida esperada
- Establece el formato HTML requerido
- Mantiene consistencia entre motores
- Incluye instrucciones espec√≠ficas de formateo

### **Transcripciones Consolidadas**
Archivo de texto que contiene:
- Todas las transcripciones de una sesi√≥n de procesamiento
- Formato: `KK-F1-v1: [contenido]`
- Timestamp de procesamiento
- Estad√≠sticas de rendimiento

### **Estructura Web Separada**
Organizaci√≥n de archivos HTML por motor:
```
proyecto/
‚îú‚îÄ‚îÄ index-openai.html      # √çndice OpenAI
‚îú‚îÄ‚îÄ index-ollama.html      # √çndice Ollama  
‚îú‚îÄ‚îÄ index-deepseek.html    # √çndice DeepSeek
‚îî‚îÄ‚îÄ www/
    ‚îú‚îÄ‚îÄ openai/           # Fases OpenAI
    ‚îú‚îÄ‚îÄ ollama/           # Fases Ollama
    ‚îî‚îÄ‚îÄ deepseek/         # Fases DeepSeek
```

## üìÑ Formatos y Protocolos

### **Segmentaci√≥n por Fases**
Divisi√≥n del contenido en secciones tem√°ticas:
- **Fase 1**: Introducci√≥n y conceptos b√°sicos
- **Fase 2**: Desarrollo t√©cnico detallado  
- **Fase 3**: Ejemplos pr√°cticos y aplicaciones
- **Fase 4**: Conclusiones y pr√≥ximos pasos

### **Hash de Verificaci√≥n**
C√≥digo √∫nico MD5 de 8 caracteres que:
- Identifica respuestas √∫nicas de IA
- Detecta respuestas truncadas o incompletas
- Permite validaci√≥n de integridad
- Facilita debugging de generaci√≥n

### **Enlaces Relativos**
Sistema de navegaci√≥n HTML que:
- Conecta index con archivos de fase
- Mantiene estructura independiente por motor
- Permite navegaci√≥n local sin servidor web
- Se auto-repara con utilidad `reparar_enlaces.py`

## üîß Configuraci√≥n y Variables

### **Variables de Entorno**
Configuraciones del sistema almacenadas en `.env`:
- `OPENAI_API_KEY`: Clave de autenticaci√≥n OpenAI
- `WHISPER_MODEL`: Versi√≥n de Whisper a utilizar
- `OLLAMA_HOST`: URL del servidor Ollama local
- `*_MAX_TOKENS`: L√≠mites de tokens por motor

### **Compute Type**
Precisi√≥n num√©rica para c√°lculos GPU:
- `float32`: M√°xima precisi√≥n, m√°s lento
- `float16`: Equilibrio √≥ptimo velocidad/precisi√≥n
- `int8`: Mayor velocidad, menor precisi√≥n

### **Temperatura de IA**
Par√°metro que controla creatividad vs consistencia:
- `0.0`: Respuestas completamente deterministas
- `0.1`: Ligeramente variable, mantiene consistencia
- `1.0`: Alta creatividad y variabilidad

## üìä M√©tricas y Rendimiento

### **Factor de Velocidad**
Ratio entre tiempo real del v√≠deo y tiempo de transcripci√≥n:
- `1x`: Transcripci√≥n toma tanto tiempo como duraci√≥n del v√≠deo
- `7-8x`: Transcripci√≥n 7-8 veces m√°s r√°pida que tiempo real
- Depende de hardware, modelo y complejidad del audio

### **Tokens**
Unidades de texto procesadas por modelos de IA:
- **Token**: Fragmento de palabra, palabra completa o car√°cter
- **L√≠mite de contexto**: M√°ximo tokens de entrada
- **L√≠mite de salida**: M√°ximo tokens generados
- Aproximadamente: 1 token ‚âà 0.75 palabras en espa√±ol

### **Rate Limiting**
L√≠mites de velocidad impuestos por APIs:
- **OpenAI**: Requests por minuto y tokens por minuto
- **Ollama**: Sin l√≠mites (local)
- **Backoff**: Espera autom√°tica cuando se alcanzan l√≠mites

## üîç Debugging y Diagn√≥sticos

### **Logging**
Sistema de registro de eventos del sistema:
- **INFO**: Operaciones normales
- **WARNING**: Situaciones inusuales pero manejables
- **ERROR**: Fallos que impiden operaci√≥n normal
- **DEBUG**: Informaci√≥n detallada para diagn√≥stico

### **Truncamiento**
Corte de respuesta de IA debido a l√≠mites:
- Detectado por ausencia de etiquetas de cierre HTML
- Activado por l√≠mites de tokens o tiempo
- Se maneja con sistema de continuaci√≥n autom√°tica

### **Regex Patterns**
Expresiones regulares para procesamiento de texto:
- Extracci√≥n de bloques HTML
- Detecci√≥n de nombres de archivo
- Correcci√≥n de enlaces relativos
- Validaci√≥n de formato de respuesta

## üåê Tecnolog√≠as Web

### **HTML Sem√°ntico**
Estructura HTML que utiliza:
- Etiquetas sem√°nticamente correctas (`<nav>`, `<main>`, `<section>`)
- Atributos de accesibilidad (`aria-*`, `role`)
- Meta tags para responsividad y SEO
- Enlaces de navegaci√≥n intuitivos

### **CSS Responsive**
Hojas de estilo que se adaptan a:
- Diferentes tama√±os de pantalla
- Dispositivos m√≥viles y desktop
- Modo oscuro y claro
- Distintas resoluciones

### **JavaScript Vanilla**
Funcionalidad interactiva sin frameworks:
- Navegaci√≥n suave entre secciones
- Animaciones y transiciones
- Mejora progresiva (funciona sin JS)
- Rendimiento optimizado

## üêç Python y Dependencias

### **Virtual Environment (venv)**
Entorno aislado de Python que:
- Separa dependencias del sistema
- Evita conflictos entre proyectos
- Permite versiones espec√≠ficas de paquetes
- Facilita reproducibilidad

### **Requirements.txt**
Archivo que especifica:
- Dependencias exactas del proyecto
- Versiones espec√≠ficas de paquetes
- Separaci√≥n entre producci√≥n y desarrollo
- Instalaci√≥n autom√°tica con `pip install -r`

### **Pathlib**
Biblioteca moderna de Python para manejo de rutas:
- Sintaxis orientada a objetos
- Compatibilidad multiplataforma
- Operaciones seguras de archivos
- Mejor que `os.path` para proyectos nuevos

---

**üí° Tip**: Si encuentras un t√©rmino t√©cnico no listado aqu√≠, consulta la [API Reference](API_REFERENCE.md) para detalles t√©cnicos espec√≠ficos.